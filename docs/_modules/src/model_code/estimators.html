

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <title>src.model_code.estimators &mdash; Covid vaccination models  documentation</title>



  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />










  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->


      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>

    <script type="text/javascript" src="../../../_static/js/theme.js"></script>


    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
</head>

<body class="wy-body-for-nav">


  <div class="wy-grid-for-nav">

    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



            <a href="../../../index.html" class="icon icon-home"> Covid vaccination models



          </a>







<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div>


        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">






              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../original_data.html">Original data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data_management.html">Data management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analysis.html">Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../final.html">Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model_code.html">Model code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model_specs.html">Model specifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../references.html">References</a></li>
</ul>



        </div>

      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">


      <nav class="wy-nav-top" aria-label="top navigation">

          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Covid vaccination models</a>

      </nav>


      <div class="wy-nav-content">

        <div class="rst-content">



















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">

      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>

          <li><a href="../../index.html">Module code</a> &raquo;</li>

      <li>src.model_code.estimators</li>


      <li class="wy-breadcrumbs-aside">

      </li>

  </ul>


  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">

  <h1>Source code for src.model_code.estimators</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">njit</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">linalg</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>


<div class="viewcode-block" id="standardize_input"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.standardize_input">[docs]</a><span class="k">def</span> <span class="nf">standardize_input</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Standardizes the regressor matrix and the dependent vector.</span>
<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1) or (n, )</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: tuple containing:</span>

<span class="sd">            **X_standardized** (*np.ndarray*): standardized regressor matrix of shape (n, p) \n</span>
<span class="sd">            **y_standardized** (*np.ndarray*): standardized vector of the dependent variable *y*, of shape (n, 1) or (n, ) \n</span>
<span class="sd">            **x_mean** (*np.ndarray*): column means of the regressor matrix of shape (p, ) \n</span>
<span class="sd">            **x_std** (*np.ndarray*): column standard deviations of the regressor matrix of shape (p, ) \n</span>
<span class="sd">            **y_mean** (*np.float64*): mean of the vector of the dependent variable *y* \n</span>
<span class="sd">            **y_std** (*np.float64*): standard deviation of the vector of the dependent variable *y*</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x_std</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="n">X_standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">x_std</span>
    <span class="n">y_standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_std</span>

    <span class="k">return</span> <span class="n">X_standardized</span><span class="p">,</span> <span class="n">y_standardized</span><span class="p">,</span> <span class="n">x_mean</span><span class="p">,</span> <span class="n">x_std</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span></div>


<div class="viewcode-block" id="count_non_zero_coeffs"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.count_non_zero_coeffs">[docs]</a><span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">count_non_zero_coeffs</span><span class="p">(</span><span class="n">theta_vec</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Determines the cardinality of the non-zero elements of a given input vector *theta_vec*.</span>

<span class="sd">    Args:</span>
<span class="sd">        theta_vec (np.ndarray): 1d array (p, ) representation of a coefficient vector</span>

<span class="sd">    Returns:</span>
<span class="sd">        **s** (*int*): cardinality of the non-zero elements of *theta_vec*</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">theta_vec</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">1e-04</span><span class="p">:</span>
            <span class="n">s</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">s</span></div>


<div class="viewcode-block" id="soft_threshold"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.soft_threshold">[docs]</a><span class="k">def</span> <span class="nf">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Soft threshold function used for standardized data within the lasso regression.</span>

<span class="sd">    Args:</span>
<span class="sd">        rho (float): defined as :math:`\\rho := X_j^T (y - y_{pred} + \\theta_j \\cdot X_j)`,</span>
<span class="sd">            where :math:`X_j` is the *j*-th column of the regressor matrix, *y* is the dependent variable</span>
<span class="sd">            vector, :math:`y_{pred} := X \\cdot \\theta` (projection), and :math:`\\theta` the coefficient vector.</span>
<span class="sd">        lamda (float): non-negative regularization parameter in the l1-penalty term of the lasso</span>
<span class="sd">        w (float): weight for a given coefficient within the l1-penalty term of the adaptive lasso</span>

<span class="sd">    Returns:</span>
<span class="sd">        (*float*): proximal mapping of the l1-norm; solution of coordinate descent for the update step in lasso</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">rho</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">lamda</span> <span class="o">*</span> <span class="n">w</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">rho</span> <span class="o">+</span> <span class="n">lamda</span> <span class="o">*</span> <span class="n">w</span>
    <span class="k">elif</span> <span class="n">rho</span> <span class="o">&gt;</span> <span class="n">lamda</span> <span class="o">*</span> <span class="n">w</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">rho</span> <span class="o">-</span> <span class="n">lamda</span> <span class="o">*</span> <span class="n">w</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span></div>


<div class="viewcode-block" id="soft_threshold_numba"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.soft_threshold_numba">[docs]</a><span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">soft_threshold_numba</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Just-in-time compiled version of the *soft_threshold* function used within the lasso regression&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">rho</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">lamda</span> <span class="o">*</span> <span class="n">w</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">rho</span> <span class="o">+</span> <span class="n">lamda</span> <span class="o">*</span> <span class="n">w</span>
    <span class="k">elif</span> <span class="n">rho</span> <span class="o">&gt;</span> <span class="n">lamda</span> <span class="o">*</span> <span class="n">w</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">rho</span> <span class="o">-</span> <span class="n">lamda</span> <span class="o">*</span> <span class="n">w</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span></div>


<div class="viewcode-block" id="get_lamda_path_numba"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.get_lamda_path_numba">[docs]</a><span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">get_lamda_path_numba</span><span class="p">(</span><span class="n">X_std</span><span class="p">,</span> <span class="n">y_std</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Just-in-time compiled version of the *get_lamda_path* function used within the lasso regression&quot;&quot;&quot;</span>

    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.0001</span>
    <span class="n">K</span> <span class="o">=</span> <span class="mi">100</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X_std</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">y_std</span> <span class="o">=</span> <span class="n">y_std</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="n">p</span><span class="p">:</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.01</span>

    <span class="n">lambda_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X_std</span> <span class="o">*</span> <span class="n">y_std</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span> <span class="o">/</span> <span class="n">n</span>
    <span class="n">lamda_path</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lambda_max</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lambda_max</span> <span class="o">*</span> <span class="n">epsilon</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="n">K</span><span class="p">))</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">lamda_path</span></div>


<div class="viewcode-block" id="get_lamda_path"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.get_lamda_path">[docs]</a><span class="k">def</span> <span class="nf">get_lamda_path</span><span class="p">(</span><span class="n">X_std</span><span class="p">,</span> <span class="n">y_std</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Calculates a data-dependent sequence of lambdas, for which we want to solve the lasso optimization problem.</span>
<span class="sd">    This approach follows the one used in *glmnet* package in R.</span>

<span class="sd">    Args:</span>
<span class="sd">        X_std (np.ndarray): standardized regressor matrix of shape (n, p)</span>
<span class="sd">        y_std (np.ndarray): standardized vector of the dependent variable *y*, of shape (n, 1) or (n, )</span>
<span class="sd">        epsilon (float): parameter determining the lower bound of the lambda sequence</span>
<span class="sd">        K (int): parameter determining the number of elements within the lambda sequence</span>

<span class="sd">    Returns:</span>
<span class="sd">        **lamda_path** (*np.ndarray*): data-dependent sequence of lambdas (optimization path for lasso)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X_std</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">y_std</span> <span class="o">=</span> <span class="n">y_std</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># to ensure that matrix inversion is stable in case that p &gt; n</span>
    <span class="k">if</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="n">p</span><span class="p">:</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.01</span>

    <span class="c1"># data-dependent part from glmnet</span>
    <span class="n">lambda_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X_std</span> <span class="o">*</span> <span class="n">y_std</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span> <span class="o">/</span> <span class="n">n</span>

    <span class="c1"># transformation such that we get many lambda elements close to zero, and a few large ones</span>
    <span class="n">lamda_path</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
            <span class="n">start</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lambda_max</span><span class="p">),</span> <span class="n">stop</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lambda_max</span> <span class="o">*</span> <span class="n">epsilon</span><span class="p">),</span> <span class="n">num</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">lamda_path</span></div>


<div class="viewcode-block" id="update_coeffs"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.update_coeffs">[docs]</a><span class="k">def</span> <span class="nf">update_coeffs</span><span class="p">(</span>
    <span class="n">X_std</span><span class="p">,</span>
    <span class="n">y_std</span><span class="p">,</span>
    <span class="n">theta</span><span class="p">,</span>
    <span class="n">active_set</span><span class="p">,</span>
    <span class="n">penalty_factors</span><span class="p">,</span>
    <span class="n">intercept</span><span class="p">,</span>
    <span class="n">lamda</span><span class="p">,</span>
    <span class="n">thresh</span><span class="p">,</span>
    <span class="n">active_thresh</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the update of the coefficients within each loop of *active_set_lasso*.</span>

<span class="sd">    Args:</span>
<span class="sd">        X_std (np.ndarray): standardized regressor matrix of shape (n, p)</span>
<span class="sd">        y_std (np.ndarray): standardized vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        theta (np.ndarray): vector of coefficients of shape (p, 1)</span>
<span class="sd">        active_set (np.ndarray): indeces of coefficients to consider in the update, i.e. these</span>
<span class="sd">            coefficients are not zero and still active</span>
<span class="sd">        penalty_factors (np.ndarray): vector of penalties that function as weights for the coefficients</span>
<span class="sd">            within the l1-penalty term of the adaptive lasso; later used in the *soft_threshold* function.</span>
<span class="sd">            The shape must be (p, 1)</span>
<span class="sd">        intercept (bool): logical value whether an intercept should be used when fitting (adaptive) lasso</span>
<span class="sd">        lamda (float): non-negative regularization parameter in the l1-penalty term of the lasso</span>
<span class="sd">        thresh (float): threshold for determining whether the update was small enough to classify the coefficient</span>
<span class="sd">            as converged</span>
<span class="sd">        active_thresh (float): threshold for determining whether the coefficient is still different enough from zero</span>
<span class="sd">            to be considered active</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: tuple containing:</span>

<span class="sd">            **theta** (*np.ndarray*): updated vector of coefficients of shape (p, 1) \n</span>
<span class="sd">            **active_set** (*np.ndarray*): indeces of coefficients to consider in the next cycle, i.e. updated version of *active_set* \n</span>
<span class="sd">            **active_set_converged** (*bool*): Logical value whether all ex ante active coefficients have converged within this cycle</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># set up two logical vectors for the active_set classication later</span>
    <span class="n">active_set_converged_check</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">),),</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">active_set_update</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">),),</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># main update step</span>
    <span class="k">for</span> <span class="n">subindex</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">active_set</span><span class="p">):</span>
        <span class="n">w_j</span> <span class="o">=</span> <span class="n">penalty_factors</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">X_j</span> <span class="o">=</span> <span class="n">X_std</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">X_std</span> <span class="o">@</span> <span class="n">theta</span>
        <span class="n">rho</span> <span class="o">=</span> <span class="n">X_j</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y_std</span> <span class="o">-</span> <span class="n">y_pred</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_j</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X_j</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">/</span> <span class="n">z</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">active_thresh</span><span class="p">:</span>
                    <span class="n">active_set_update</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                    <span class="n">active_set_converged_check</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">active_thresh</span><span class="p">:</span>
                    <span class="n">active_set_update</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                    <span class="n">active_set_converged_check</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">active_thresh</span><span class="p">:</span>
                <span class="n">active_set_update</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                <span class="n">active_set_converged_check</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>

    <span class="c1"># test whether all ex ante active coefficients have converged within this cycle</span>
    <span class="n">active_set_converged</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">active_set_converged_check</span><span class="p">)</span>

    <span class="c1"># remove coefficients from the active set that were too close to zero</span>
    <span class="n">active_set</span> <span class="o">=</span> <span class="n">active_set</span><span class="p">[</span><span class="n">active_set_update</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">theta</span><span class="p">,</span> <span class="n">active_set</span><span class="p">,</span> <span class="n">active_set_converged</span></div>


<div class="viewcode-block" id="naive_lasso"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.naive_lasso">[docs]</a><span class="k">def</span> <span class="nf">naive_lasso</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">penalty_factors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">lamda_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Naive coordinate descent implementation of the basic lasso optimization problem without stopping criterion</span>
<span class="sd">    except the maximum number of iterations.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        penalty_factors (np.ndarray): vector of penalties that function as weights for the coefficients</span>
<span class="sd">            within the l1-penalty term of the adaptive lasso; later used in the *soft_threshold* function.</span>
<span class="sd">            The shape must be (p, 1). If none are provided, the function defaults to providing a vector of ones,</span>
<span class="sd">            which is the standard lasso version.</span>
<span class="sd">        theta (np.ndarray): initial starting values for the vector of coefficients of shape (p, 1).</span>
<span class="sd">            If none are provided, the function defaults to setting each coefficient to zero initially.</span>
<span class="sd">        lamda_path (np.ndarray): sequence of lambda values to solve the lasso problem for.</span>
<span class="sd">            If none are provided, the function provides a data-dependent sequence by default.</span>
<span class="sd">        num_iters (int): Maximum number of cycles to update the coefficients; usually convergence is</span>
<span class="sd">            reached in under 100 iterations. Defaults to 100.</span>
<span class="sd">        intercept (bool): logical value whether an intercept should be used when fitting (adaptive) lasso</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: list of dicts, each containing:</span>

<span class="sd">            **lamda** (*float*): non-negative regularization parameter in the l1-penalty term of the lasso and element of lamda_path \n</span>
<span class="sd">            **theta_std** (*np.ndarray*): optimal lasso coefficients on the standardized scale for the given lambda in the dictionary, shape (p, ) \n</span>
<span class="sd">            **theta_nat** (*np.ndarray*): optimal lasso coefficients on the original scale for the given lambda in the dictionary, shape (p, )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_mean</span><span class="p">,</span> <span class="n">x_std</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="n">standardize_input</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">lamda_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">get_lamda_path_numba</span><span class="p">(</span><span class="n">X_std</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y_std</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">lamda_path</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">penalty_factors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">penalty_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">lamda</span> <span class="ow">in</span> <span class="n">path</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;lamda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lamda</span> <span class="o">/</span> <span class="n">n</span>

        <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
                <span class="n">w_j</span> <span class="o">=</span> <span class="n">penalty_factors</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">X_j</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">theta</span>
                <span class="n">rho</span> <span class="o">=</span> <span class="n">X_j</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_j</span><span class="p">)</span>
                <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X_j</span><span class="p">))</span>

                <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">/</span> <span class="n">z</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_nat</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
        <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_0</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x_mean</span> <span class="o">/</span> <span class="n">x_std</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="p">)</span> <span class="o">*</span> <span class="n">y_std</span> <span class="o">+</span> <span class="n">y_mean</span>
            <span class="n">theta_betas</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
            <span class="n">theta_nat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">theta_betas</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">theta_0</span><span class="p">)</span>

        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;theta_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;theta_nat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_nat</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="eps_thresh_lasso"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.eps_thresh_lasso">[docs]</a><span class="k">def</span> <span class="nf">eps_thresh_lasso</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">penalty_factors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">lamda_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">thresh</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Improved coordinate descent implementation of the basic lasso optimization problem with</span>
<span class="sd">    threshold as stopping criterion. Cycling is stopped if the absolute difference between each updated</span>
<span class="sd">    theta and its former value is below the threshold *thresh*.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        penalty_factors (np.ndarray): vector of penalties that function as weights for the coefficients</span>
<span class="sd">            within the l1-penalty term of the adaptive lasso; later used in the *soft_threshold* function.</span>
<span class="sd">            The shape must be (p, 1). If none are provided, the function defaults to providing a vector of ones,</span>
<span class="sd">            which is the standard lasso version.</span>
<span class="sd">        theta (np.ndarray): initial starting values for the vector of coefficients of shape (p, 1). If none</span>
<span class="sd">            are provided, the function defaults to setting each coefficient to zero initially.</span>
<span class="sd">        lamda_path (np.ndarray): sequence of lambda values to solve the lasso problem for. If none are</span>
<span class="sd">            provided, the function provides a data-dependent sequence by default.</span>
<span class="sd">        num_iters (int): Maximum number of cycles to update the coefficients; usually convergence is reached</span>
<span class="sd">            in under 100 iterations. Defaults to 100.</span>
<span class="sd">        intercept (bool): logical value whether an intercept should be used when fitting (adaptive) lasso</span>
<span class="sd">        thresh (float): determines the relevant threshold for the  absolute difference between each updated</span>
<span class="sd">            theta and its former value</span>


<span class="sd">    Returns:</span>
<span class="sd">        list: list of dicts, each containing:</span>

<span class="sd">            **lamda** (*float*): non-negative regularization parameter in the l1-penalty term of the lasso and element of lamda_path \n</span>
<span class="sd">            **theta_std** (*np.ndarray*): optimal lasso coefficients on the standardized scale for the given lambda in the dictionary, shape (p, ) \n</span>
<span class="sd">            **theta_nat** (*np.ndarray*): optimal lasso coefficients on the original scale for the given lambda in the dictionary, shape (p, )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_mean</span><span class="p">,</span> <span class="n">x_std</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="n">standardize_input</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">lamda_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">get_lamda_path_numba</span><span class="p">(</span><span class="n">X_std</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y_std</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">lamda_path</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">penalty_factors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">penalty_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">lamda</span> <span class="ow">in</span> <span class="n">path</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;lamda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lamda</span> <span class="o">/</span> <span class="n">n</span>
        <span class="n">tol_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">p</span><span class="p">,),</span> <span class="kc">False</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">tol_vals</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
                    <span class="n">w_j</span> <span class="o">=</span> <span class="n">penalty_factors</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">X_j</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">theta</span>
                    <span class="n">rho</span> <span class="o">=</span> <span class="n">X_j</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_j</span><span class="p">)</span>
                    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X_j</span><span class="p">))</span>

                    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">rho</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                                <span class="n">tol_vals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">/</span> <span class="n">z</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">if</span> <span class="p">(</span>
                                <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span>
                                    <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
                                <span class="p">)</span>
                                <span class="o">&lt;</span> <span class="n">thresh</span>
                            <span class="p">):</span>
                                <span class="n">tol_vals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="p">(</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">))</span>
                            <span class="o">&lt;</span> <span class="n">thresh</span>
                        <span class="p">):</span>
                            <span class="n">tol_vals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_nat</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
        <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_0</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x_mean</span> <span class="o">/</span> <span class="n">x_std</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="p">)</span> <span class="o">*</span> <span class="n">y_std</span> <span class="o">+</span> <span class="n">y_mean</span>
            <span class="n">theta_betas</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
            <span class="n">theta_nat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">theta_betas</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">theta_0</span><span class="p">)</span>

        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;theta_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;theta_nat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_nat</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="eps_thresh_lasso_warm_start"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.eps_thresh_lasso_warm_start">[docs]</a><span class="k">def</span> <span class="nf">eps_thresh_lasso_warm_start</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">penalty_factors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">lamda_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">thresh</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Further improved coordinate descent implementation of the basic lasso optimization problem with threshold as</span>
<span class="sd">    stopping criterion and the usage of *warm_starts*. Cycling is stopped if the absolute difference between each updated</span>
<span class="sd">    theta and its former value is below the threshold *thresh*, and warm starts reuse the previously learned optimal</span>
<span class="sd">    coefficients as starting values for theta in the optimization for the next lambda element in the *lamda_path*.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        penalty_factors (np.ndarray): vector of penalties that function as weights for the coefficients within</span>
<span class="sd">            the l1-penalty term of the adaptive lasso; later used in the *soft_threshold* function. The shape must</span>
<span class="sd">            be (p, 1). If none are provided, the function defaults to providing a vector of ones, which is</span>
<span class="sd">            the standard lasso version.</span>
<span class="sd">        theta (np.ndarray): initial starting values for the vector of coefficients of shape (p, 1).</span>
<span class="sd">            If none are provided, the function defaults to setting each coefficient to zero initially.</span>
<span class="sd">        lamda_path (np.ndarray): sequence of lambda values to solve the lasso problem for.</span>
<span class="sd">            If none are provided, the function provides a data-dependent sequence by default.</span>
<span class="sd">        num_iters (int): Maximum number of cycles to update the coefficients; usually convergence is reached in</span>
<span class="sd">            under 100 iterations. Defaults to 100.</span>
<span class="sd">        intercept (bool): logical value whether an intercept should be used when fitting (adaptive) lasso</span>
<span class="sd">        thresh (float): threshold for determining whether the update was small enough to classify</span>
<span class="sd">            the coefficient as converged</span>
<span class="sd">        warm_start (bool): Logical value determining whether the *warm_starts* feature should be used.</span>


<span class="sd">    Returns:</span>
<span class="sd">        list: list of dicts, each containing:</span>

<span class="sd">            **lamda** (*float*): non-negative regularization parameter in the l1-penalty term of the lasso and element of lamda_path \n</span>
<span class="sd">            **theta_std** (*np.ndarray*): optimal lasso coefficients on the standardized scale for the given lambda in the dictionary, shape (p, ) \n</span>
<span class="sd">            **theta_nat** (*np.ndarray*): optimal lasso coefficients on the original scale for the given lambda in the dictionary, shape (p, )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_mean</span><span class="p">,</span> <span class="n">x_std</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="n">standardize_input</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">lamda_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">get_lamda_path_numba</span><span class="p">(</span><span class="n">X_std</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y_std</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">lamda_path</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">penalty_factors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">penalty_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">lamda</span> <span class="ow">in</span> <span class="n">path</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">warm_start</span><span class="p">:</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;lamda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lamda</span> <span class="o">/</span> <span class="n">n</span>
        <span class="n">tol_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">p</span><span class="p">,),</span> <span class="kc">False</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">tol_vals</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
                    <span class="n">w_j</span> <span class="o">=</span> <span class="n">penalty_factors</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">X_j</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">theta</span>
                    <span class="n">rho</span> <span class="o">=</span> <span class="n">X_j</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_j</span><span class="p">)</span>
                    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X_j</span><span class="p">))</span>

                    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">rho</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                                <span class="n">tol_vals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">/</span> <span class="n">z</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">if</span> <span class="p">(</span>
                                <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span>
                                    <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
                                <span class="p">)</span>
                                <span class="o">&lt;</span> <span class="n">thresh</span>
                            <span class="p">):</span>
                                <span class="n">tol_vals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="p">(</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">))</span>
                            <span class="o">&lt;</span> <span class="n">thresh</span>
                        <span class="p">):</span>
                            <span class="n">tol_vals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_nat</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
        <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_0</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x_mean</span> <span class="o">/</span> <span class="n">x_std</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="p">)</span> <span class="o">*</span> <span class="n">y_std</span> <span class="o">+</span> <span class="n">y_mean</span>
            <span class="n">theta_betas</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
            <span class="n">theta_nat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">theta_betas</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">theta_0</span><span class="p">)</span>

        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;theta_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;theta_nat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_nat</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="active_set_lasso"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.active_set_lasso">[docs]</a><span class="k">def</span> <span class="nf">active_set_lasso</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">penalty_factors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">lamda_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">thresh</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">active_thresh</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Even more improved coordinate descent implementation of the lasso optimization problem with threshold as</span>
<span class="sd">    stopping criterion, the usage of *warm_starts*, and the usage of *active sets*. Cycling is stopped if the absolute</span>
<span class="sd">    difference between each updated theta and its former value is below the threshold *thresh*, and warm starts</span>
<span class="sd">    reuses the previously learned optimal coefficients as starting values for theta in the optimization for the next</span>
<span class="sd">    lambda element in the *lamda_path*. After an initial cycle through all *p* variables, the *active_set* feature</span>
<span class="sd">    restricts further iterations to the *active set* till convergence; and finally does one more cycle through all *p*</span>
<span class="sd">    variables to check if the active set has changed. This helps especially when *p* is large. Uses the base function</span>
<span class="sd">    *update_coeffs* for readability.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        penalty_factors (np.ndarray): vector of penalties that function as weights for the coefficients within</span>
<span class="sd">            the l1-penalty term of the adaptive lasso; later used in the *soft_threshold* function.</span>
<span class="sd">            The shape must be (p, 1). If none are provided, the function defaults to providing a vector of ones,</span>
<span class="sd">            which is the standard lasso version</span>
<span class="sd">        theta (np.ndarray): initial starting values for the vector of coefficients of shape (p, 1). If none are provided,</span>
<span class="sd">            the function defaults to setting each coefficient to zero initially</span>
<span class="sd">        lamda_path (np.ndarray): sequence of lambda values to solve the lasso problem for. If none are provided, the</span>
<span class="sd">            function provides a data-dependent sequence by default</span>
<span class="sd">        num_iters (int): Maximum number of cycles to update the coefficients; usually convergence is reached in</span>
<span class="sd">            under 100 iterations. Defaults to 100</span>
<span class="sd">        intercept (bool): logical value whether an intercept should be used when fitting (adaptive) lasso</span>
<span class="sd">        thresh (float): threshold for determining whether the update was small enough to classify</span>
<span class="sd">            the coefficient as converged</span>
<span class="sd">        active_thresh (float): threshold for determining whether the coefficient is still different</span>
<span class="sd">            enough from zero to be considered active</span>
<span class="sd">        warm_start (bool): Logical value determining whether the *warm_starts* feature should be used</span>


<span class="sd">    Returns:</span>
<span class="sd">        list: list of dicts, each containing:</span>

<span class="sd">            **lamda** (*float*): non-negative regularization parameter in the l1-penalty term of the lasso and element of lamda_path \n</span>
<span class="sd">            **theta_std** (*np.ndarray*): optimal lasso coefficients on the standardized scale for the given lambda in the dictionary, shape (p, ) \n</span>
<span class="sd">            **theta_nat** (*np.ndarray*): optimal lasso coefficients on the original scale for the given lambda in the dictionary, shape (p, )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x_mean</span><span class="p">,</span> <span class="n">x_std</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span> <span class="o">=</span> <span class="n">standardize_input</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">lamda_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">get_lamda_path_numba</span><span class="p">(</span><span class="n">X_std</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y_std</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">lamda_path</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">penalty_factors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">penalty_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">lamda</span> <span class="ow">in</span> <span class="n">path</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">warm_start</span><span class="p">:</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;lamda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lamda</span> <span class="o">/</span> <span class="n">n</span>
        <span class="n">sec_check_all_converged</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">active_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">active_set_converged</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">active_set</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">active_set_converged</span><span class="p">):</span>
                <span class="n">theta</span><span class="p">,</span> <span class="n">active_set</span><span class="p">,</span> <span class="n">active_set_converged</span> <span class="o">=</span> <span class="n">update_coeffs</span><span class="p">(</span>
                    <span class="n">X_std</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                    <span class="n">y_std</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                    <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span>
                    <span class="n">active_set</span><span class="o">=</span><span class="n">active_set</span><span class="p">,</span>
                    <span class="n">penalty_factors</span><span class="o">=</span><span class="n">penalty_factors</span><span class="p">,</span>
                    <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
                    <span class="n">lamda</span><span class="o">=</span><span class="n">lamda</span><span class="p">,</span>
                    <span class="n">thresh</span><span class="o">=</span><span class="n">thresh</span><span class="p">,</span>
                    <span class="n">active_thresh</span><span class="o">=</span><span class="n">active_thresh</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">sec_check_all_converged</span><span class="p">:</span>
                <span class="n">active_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
                <span class="n">theta</span><span class="p">,</span> <span class="n">active_set</span><span class="p">,</span> <span class="n">active_set_converged</span> <span class="o">=</span> <span class="n">update_coeffs</span><span class="p">(</span>
                    <span class="n">X_std</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
                    <span class="n">y_std</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                    <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span>
                    <span class="n">active_set</span><span class="o">=</span><span class="n">active_set</span><span class="p">,</span>
                    <span class="n">penalty_factors</span><span class="o">=</span><span class="n">penalty_factors</span><span class="p">,</span>
                    <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
                    <span class="n">lamda</span><span class="o">=</span><span class="n">lamda</span><span class="p">,</span>
                    <span class="n">thresh</span><span class="o">=</span><span class="n">thresh</span><span class="p">,</span>
                    <span class="n">active_thresh</span><span class="o">=</span><span class="n">active_thresh</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">active_set_converged</span><span class="p">:</span>
                    <span class="n">sec_check_all_converged</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_nat</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
        <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_0</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x_mean</span> <span class="o">/</span> <span class="n">x_std</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="p">)</span> <span class="o">*</span> <span class="n">y_std</span> <span class="o">+</span> <span class="n">y_mean</span>
            <span class="n">theta_betas</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
            <span class="n">theta_nat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">theta_betas</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">theta_0</span><span class="p">)</span>

        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;theta_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;theta_nat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_nat</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="lasso_numba"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.lasso_numba">[docs]</a><span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">lasso_numba</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">lamda_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">penalty_factors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">thresh</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">active_thresh</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
    <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Just-in-time compiled version of the *active_set_lasso* function.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        penalty_factors (np.ndarray): vector of penalties that function as weights for the coefficients within the</span>
<span class="sd">            l1-penalty term of the adaptive lasso; later used in the *soft_threshold* function. The shape must</span>
<span class="sd">            be (p, 1). If none are provided, the function defaults to providing a vector of ones,</span>
<span class="sd">            which is the standard lasso version</span>
<span class="sd">        theta (np.ndarray): initial starting values for the vector of coefficients of shape (p, 1).</span>
<span class="sd">            If none are provided, the function defaults to setting each coefficient to zero initially</span>
<span class="sd">        lamda_path (np.ndarray): sequence of lambda values to solve the lasso problem for. If none are provided,</span>
<span class="sd">            the function provides a data-dependent sequence by default</span>
<span class="sd">        num_iters (int): Maximum number of cycles to update the coefficients; usually convergence is reached</span>
<span class="sd">            in under 100 iterations. Defaults to 100</span>
<span class="sd">        intercept (bool): logical value whether an intercept should be used when fitting (adaptive) lasso</span>
<span class="sd">        thresh (float): threshold for determining whether the update was small enough to classify</span>
<span class="sd">            the coefficient as converged</span>
<span class="sd">        active_thresh (float): threshold for determining whether the coefficient is still different enough</span>
<span class="sd">            from zero to be considered active</span>
<span class="sd">        warm_start (bool): Logical value determining whether the *warm_starts* feature should be used</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: tuple containing:</span>

<span class="sd">            **lamdas** (*list*): list of lamdas in lamda_path for which the lasso problem has been solved \n</span>
<span class="sd">            **thetas** (*list*): list of lasso coefficient vectors on the standardized scale, for each lambda in *lamdas* one optimal coefficient vector \n</span>
<span class="sd">            **thetas_nat** (*list*): list of lasso coefficient vectors on the original scale, for each lambda in *lamdas* one optimal coefficient vector \n</span>
<span class="sd">            **BIC** (*list*): list of BIC values, one for each lambda in *lamdas* (BIC calculated from the respective model trained given a lambda value). For details see **Zou, H., Hastie, T., &amp; Tibshirani, R. (2007)**</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="n">x_mean</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="n">x_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="n">x_std</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

    <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="n">X_standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">x_std</span>
    <span class="n">y_standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_std</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">X_tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">X_tmp</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X_tmp</span>

    <span class="k">if</span> <span class="n">lamda_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">get_lamda_path_numba</span><span class="p">(</span><span class="n">X_std</span><span class="o">=</span><span class="n">X_standardized</span><span class="p">,</span> <span class="n">y_std</span><span class="o">=</span><span class="n">y_standardized</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">lamda_path</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">X_tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">X_tmp</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">X_standardized</span>
        <span class="n">X_standardized</span> <span class="o">=</span> <span class="n">X_tmp</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X_standardized</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">penalty_factors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">penalty_factors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">lamdas</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">thetas</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">thetas_nat</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">BIC</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">lamda</span> <span class="ow">in</span> <span class="n">path</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">warm_start</span><span class="p">:</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">sec_check_all_converged</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">active_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">active_set_converged</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iters</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">active_set</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">active_set_converged</span><span class="p">):</span>
                <span class="n">active_set_converged_check</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">),),</span> <span class="kc">False</span><span class="p">)</span>
                <span class="n">active_set_update</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">),),</span> <span class="kc">True</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">subindex</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">active_set</span><span class="p">):</span>
                    <span class="n">w_j</span> <span class="o">=</span> <span class="n">penalty_factors</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">X_standardized</span> <span class="o">@</span> <span class="n">theta</span>

                    <span class="n">rho</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="n">z</span> <span class="o">=</span> <span class="mf">0.0</span>

                    <span class="k">for</span> <span class="n">obs</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                        <span class="n">rho</span> <span class="o">+=</span> <span class="n">X_standardized</span><span class="p">[</span><span class="n">obs</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span>
                            <span class="n">y_standardized</span><span class="p">[</span><span class="n">obs</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                            <span class="o">-</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">obs</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                            <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">X_standardized</span><span class="p">[</span><span class="n">obs</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                        <span class="p">)</span>
                        <span class="n">z</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X_standardized</span><span class="p">[</span><span class="n">obs</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">tmp</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">/</span> <span class="n">z</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">active_thresh</span><span class="p">:</span>
                                <span class="n">active_set_update</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                                <span class="n">active_set_converged_check</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">tmp</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold_numba</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">active_thresh</span><span class="p">:</span>
                                <span class="n">active_set_update</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                                <span class="n">active_set_converged_check</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">tmp</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold_numba</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">active_thresh</span><span class="p">:</span>
                            <span class="n">active_set_update</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                            <span class="n">active_set_converged_check</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>

                <span class="n">active_set_converged</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">active_set_converged_check</span><span class="p">)</span>
                <span class="n">active_set</span> <span class="o">=</span> <span class="n">active_set</span><span class="p">[</span><span class="n">active_set_update</span><span class="p">]</span>

            <span class="k">elif</span> <span class="ow">not</span> <span class="n">sec_check_all_converged</span><span class="p">:</span>
                <span class="n">active_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

                <span class="n">active_set_converged_check</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">),),</span> <span class="kc">False</span><span class="p">)</span>
                <span class="n">active_set_update</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">active_set</span><span class="p">),),</span> <span class="kc">True</span><span class="p">)</span>

                <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X_standardized</span><span class="o">.</span><span class="n">shape</span>

                <span class="k">for</span> <span class="n">subindex</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">active_set</span><span class="p">):</span>
                    <span class="n">w_j</span> <span class="o">=</span> <span class="n">penalty_factors</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">X_standardized</span> <span class="o">@</span> <span class="n">theta</span>
                    <span class="n">rho</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="n">z</span> <span class="o">=</span> <span class="mf">0.0</span>

                    <span class="k">for</span> <span class="n">obs</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                        <span class="n">rho</span> <span class="o">+=</span> <span class="n">X_standardized</span><span class="p">[</span><span class="n">obs</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span>
                            <span class="n">y_standardized</span><span class="p">[</span><span class="n">obs</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                            <span class="o">-</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">obs</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                            <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">X_standardized</span><span class="p">[</span><span class="n">obs</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                        <span class="p">)</span>
                        <span class="n">z</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X_standardized</span><span class="p">[</span><span class="n">obs</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">tmp</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">/</span> <span class="n">z</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">active_thresh</span><span class="p">:</span>
                                <span class="n">active_set_update</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                                <span class="n">active_set_converged_check</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">tmp</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold_numba</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">active_thresh</span><span class="p">:</span>
                                <span class="n">active_set_update</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                                <span class="n">active_set_converged_check</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">tmp</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">soft_threshold_numba</span><span class="p">(</span><span class="n">rho</span><span class="p">,</span> <span class="n">lamda</span><span class="p">,</span> <span class="n">w_j</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">active_thresh</span><span class="p">:</span>
                            <span class="n">active_set_update</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">tmp</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">thresh</span><span class="p">:</span>
                            <span class="n">active_set_converged_check</span><span class="p">[</span><span class="n">subindex</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="n">theta</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>

                <span class="n">active_set_converged</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">active_set_converged_check</span><span class="p">)</span>
                <span class="n">active_set</span> <span class="o">=</span> <span class="n">active_set</span><span class="p">[</span><span class="n">active_set_update</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">active_set_converged</span><span class="p">:</span>
                    <span class="n">sec_check_all_converged</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_tmp</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
        <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">theta_0</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x_mean</span> <span class="o">/</span> <span class="n">x_std</span><span class="p">)</span> <span class="o">*</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="p">)</span> <span class="o">*</span> <span class="n">y_std</span> <span class="o">+</span> <span class="n">y_mean</span>
            <span class="n">theta_betas</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="n">x_std</span> <span class="o">*</span> <span class="n">y_std</span>
            <span class="n">theta_tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">p</span><span class="p">,))</span>
            <span class="n">theta_tmp</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">theta_betas</span>
            <span class="n">theta_tmp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_0</span>

        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">theta_bic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">theta_bic</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_tmp</span>
        <span class="n">residuals_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">theta_bic</span><span class="p">))</span>
        <span class="n">df_lamda</span> <span class="o">=</span> <span class="n">count_non_zero_coeffs</span><span class="p">(</span><span class="n">theta_vec</span><span class="o">=</span><span class="n">theta_bic</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">BIC_lasso</span> <span class="o">=</span> <span class="n">residuals_hat</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">y_std</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="n">df_lamda</span>

        <span class="n">lamdas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lamda</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
        <span class="n">thetas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">thetas_nat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta_tmp</span><span class="p">)</span>
        <span class="n">BIC</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BIC_lasso</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">lamdas</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">thetas_nat</span><span class="p">,</span> <span class="n">BIC</span></div>


<div class="viewcode-block" id="adaptive_lasso"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.adaptive_lasso">[docs]</a><span class="k">def</span> <span class="nf">adaptive_lasso</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="p">,</span>
    <span class="n">intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">lamda_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">gamma_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">first_stage</span><span class="o">=</span><span class="s2">&quot;OLS&quot;</span><span class="p">,</span>
    <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">out_as_df</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Basic implementation of the adaptive lasso from **Zou, H. (2006)**.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        intercept (bool): logical value whether an intercept should be used when fitting lasso or OLS</span>
<span class="sd">        lamda_path (np.ndarray): sequence of lambda values to solve the lasso problem for. If none are provided,</span>
<span class="sd">            the function provides a data-dependent sequence by default</span>
<span class="sd">        gamma_path (np.ndarray): sequence of gamma values to solve the lasso problem for (see paper above for more details on gamma).</span>
<span class="sd">            If none are provided, the function provides a simple yet broad enough sequence by default</span>
<span class="sd">        first_stage (str): Options are &quot;OLS&quot; and &quot;Lasso&quot; currently. Determines which method should be used for</span>
<span class="sd">            getting initial first-stage estimates for the coefficient vector. Defaults to &quot;OLS&quot;. If &quot;Lasso&quot;</span>
<span class="sd">            is chosen, the full *lamda_path* is calculated and the lamda that minimzes BIC is taken as a final</span>
<span class="sd">            estimate (for selection consistency), following **Zou, H., Hastie, T., &amp; Tibshirani, R. (2007)**</span>
<span class="sd">        num_iters (int): Maximum number of cycles to update the coefficients; usually convergence is reached in</span>
<span class="sd">            under 100 iterations. Defaults to 100</span>
<span class="sd">        out_as_df (bool): Logical value determining whether the output should be in pd.DataFrame format instead</span>
<span class="sd">            of lists. This is necessary for later use with the *cv_adaptive_lasso* function</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: if out_as_df = False, tuple containing:</span>

<span class="sd">            **path_gamma** (*np.ndarray*): sequence of gamma values for which the lasso problem has actually been solved \n</span>
<span class="sd">            **results** (*list*): list of tuples returned by calls to &quot;lasso_numba&quot;, one tuple for each gamma in *path_gamma* \n</span>
<span class="sd">            **weight_path** (*list*): list of np.ndarrays, each consisting of the coefficient weights used for solving lasso (for each gamma one)</span>

<span class="sd">        if out_as_df = True, pd.DataFrame:</span>
<span class="sd">            **df** (*pd.DataFrame*): dataframe of results, consisting of the *path_gamma* and *path_lamda* vectors as its multiindex; and the standardized coefficient vectors, original scaled coefficient vectors, as well as gamma_weight vectors as its cell entries.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">if</span> <span class="n">gamma_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">path_gamma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">path_gamma</span> <span class="o">=</span> <span class="n">gamma_path</span>

    <span class="k">if</span> <span class="n">first_stage</span> <span class="o">==</span> <span class="s2">&quot;OLS&quot;</span><span class="p">:</span>
        <span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span>
    <span class="k">elif</span> <span class="n">first_stage</span> <span class="o">==</span> <span class="s2">&quot;Lasso&quot;</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">lasso_numba</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># taking the lasso fit that minimizes the BIC estimate</span>
        <span class="n">index_lamda_opt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">3</span><span class="p">]))[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># remove the intercept, since it should not be penalized</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">index_lamda_opt</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
            <span class="s2">&quot;This feature has so far only been implemented for OLS and Lasso as its first-stage estimators.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># avoiding numerical issues, division by zero etc.</span>
    <span class="n">coeffs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1.00e-15</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.00e-15</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">weight_path</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># this is the second stage, making use of the first-stage estimates from before saved in &quot;coeffs&quot;</span>
    <span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="n">path_gamma</span><span class="p">:</span>

        <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span> <span class="o">**</span> <span class="n">gamma</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span> <span class="o">**</span> <span class="n">gamma</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">lasso_numba</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">lamda_path</span><span class="o">=</span><span class="n">lamda_path</span><span class="p">,</span>
            <span class="n">penalty_factors</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
            <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">num_iters</span><span class="o">=</span><span class="n">num_iters</span><span class="p">,</span>
            <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
            <span class="n">thresh</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
            <span class="n">active_thresh</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
            <span class="n">warm_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">weight_path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">out_as_df</span><span class="p">:</span>
        <span class="n">lamda_p</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">product</span><span class="p">(</span><span class="n">path_gamma</span><span class="p">,</span> <span class="n">lamda_p</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="s2">&quot;lamda&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;theta_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;theta_nat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gamma_weights&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="s2">&quot;lamda&quot;</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">id_gamma</span><span class="p">,</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">path_gamma</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">lamda</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">id_gamma</span><span class="p">][</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">index</span> <span class="o">=</span> <span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">lamda</span><span class="p">)</span>
                <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;theta_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">id_gamma</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;theta_nat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">id_gamma</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;gamma_weights&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_path</span><span class="p">[</span><span class="n">id_gamma</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">df</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">path_gamma</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">weight_path</span></div>


<div class="viewcode-block" id="get_conf_intervals"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.get_conf_intervals">[docs]</a><span class="k">def</span> <span class="nf">get_conf_intervals</span><span class="p">(</span>
    <span class="n">lamda</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">theta_std</span><span class="p">,</span> <span class="n">theta_nat</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">X_std</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_std</span>
<span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Calculates the adaptive lasso confidence intervals of active coefficients, i.e. coefficients in *theta_std*</span>
<span class="sd">    that are distinct from zero. The calculations are based on the Standard Error Formula in chapter 3.6. in Zou, H. (2006).</span>

<span class="sd">    Args:</span>
<span class="sd">        lamda (float): non-negative regularization parameter in the l1-penalty term of the lasso</span>
<span class="sd">        weights (np.ndarray): vector of penalties/ weights for the coefficients within the l1-penalty term</span>
<span class="sd">            of the adaptive lasso. The shape must be (p, 1)</span>
<span class="sd">        theta_std (np.ndarray): vector of previously fitted adaptive lasso coefficients on standardized scale of shape (p, )</span>
<span class="sd">        theta_nat (np.ndarray): vector of previously fitted adaptive lasso coefficients on original scale of shape (p, )</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        X_std (np.ndarray): standardized regressor matrix of shape (n, p)</span>
<span class="sd">        intercept (bool): logical value whether an intercept was used while fitting the adaptive lasso</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        y_std (np.ndarray): standardized vector of the dependent variable *y*, of shape (n, 1)</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: dict containing:</span>

<span class="sd">            **beta_hat_nat_cov_mat** (*np.ndarray*): estimated asymptotic covariance matrix (on original scale) for the active set of estimated coefficients from adaptive lasso \n</span>
<span class="sd">            **beta_hat_std_cov_mat** (*np.ndarray*): estimated asymptotic covariance matrix (on standardized scale) for the active set of estimated coefficients from adaptive lasso \n</span>
<span class="sd">            **conf_intervals_nat** (*np.ndarray*): elementwise confidence intervals at the 95% confidence level for coefficients in the active set, on original scale \n</span>
<span class="sd">            **conf_intervals_std** (*np.ndarray*): elementwise confidence intervals at the 95% confidence level for coefficients in the active set, on standardized scale \n</span>
<span class="sd">            **active_set** (*np.ndarray*): the active (non-zero) set of coefficients in *theta_nat* for which confidence intervals were calculated</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">X_with_intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">X_std_with_intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X_std</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">sigma_hat_nat</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mi">1</span>
            <span class="o">/</span> <span class="n">n</span>
            <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">X_with_intercept</span> <span class="o">@</span> <span class="n">theta_nat</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_nat</span><span class="p">),</span> <span class="mi">1</span><span class="p">)))</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">sigma_hat_std</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mi">1</span>
            <span class="o">/</span> <span class="n">n</span>
            <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span>
                    <span class="n">y_std</span>
                    <span class="o">-</span> <span class="n">X_std_with_intercept</span> <span class="o">@</span> <span class="n">theta_std</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_std</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">sigma_hat_nat</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mi">1</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">theta_nat</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_nat</span><span class="p">),</span> <span class="mi">1</span><span class="p">))))</span>
        <span class="p">)</span>
        <span class="n">sigma_hat_std</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mi">1</span>
            <span class="o">/</span> <span class="n">n</span>
            <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y_std</span> <span class="o">-</span> <span class="n">X_std</span> <span class="o">@</span> <span class="n">theta_std</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_std</span><span class="p">),</span> <span class="mi">1</span><span class="p">))))</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">theta_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">theta_std</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">theta_nat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">theta_nat</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="c1"># selection of the relevant (&quot;active&quot;) columns in the regressor matrix X and in the coefficient vectors</span>
    <span class="n">active_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">theta_nat</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">))</span>

    <span class="n">X_active</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">active_set</span><span class="p">]</span>
    <span class="n">X_std_active</span> <span class="o">=</span> <span class="n">X_std</span><span class="p">[:,</span> <span class="n">active_set</span><span class="p">]</span>
    <span class="n">theta_nat_active</span> <span class="o">=</span> <span class="n">theta_nat</span><span class="p">[</span><span class="n">active_set</span><span class="p">]</span>
    <span class="n">theta_std_active</span> <span class="o">=</span> <span class="n">theta_std</span><span class="p">[</span><span class="n">active_set</span><span class="p">]</span>
    <span class="n">weights_active</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">active_set</span><span class="p">]</span>

    <span class="c1"># the steps below follow the Standard Error Formula in chapter 3.6. in Zou, H. (2006)</span>
    <span class="n">diag_std</span> <span class="o">=</span> <span class="n">weights_active</span> <span class="o">/</span> <span class="n">theta_std_active</span>
    <span class="n">diag_nat</span> <span class="o">=</span> <span class="n">weights_active</span> <span class="o">/</span> <span class="n">theta_nat_active</span>

    <span class="n">sigma_beta_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="n">diag_std</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">sigma_beta_nat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="n">diag_nat</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">main_mat_nat</span> <span class="o">=</span> <span class="n">X_active</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X_active</span> <span class="o">+</span> <span class="n">lamda</span> <span class="o">*</span> <span class="n">sigma_beta_nat</span>
    <span class="n">main_mat_std</span> <span class="o">=</span> <span class="n">X_std_active</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X_std_active</span> <span class="o">+</span> <span class="n">lamda</span> <span class="o">*</span> <span class="n">sigma_beta_std</span>

    <span class="n">main_mat_nat_inverse</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">main_mat_nat</span><span class="p">)</span>
    <span class="n">main_mat_std_inverse</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">main_mat_std</span><span class="p">)</span>

    <span class="n">beta_hat_nat_cov_mat</span> <span class="o">=</span> <span class="n">sigma_hat_nat</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">main_mat_nat_inverse</span> <span class="o">@</span> <span class="n">X_active</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X_active</span> <span class="o">@</span> <span class="n">main_mat_nat_inverse</span>
    <span class="p">)</span>
    <span class="n">beta_hat_std_cov_mat</span> <span class="o">=</span> <span class="n">sigma_hat_std</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">main_mat_std_inverse</span> <span class="o">@</span> <span class="n">X_std_active</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X_std_active</span> <span class="o">@</span> <span class="n">main_mat_std_inverse</span>
    <span class="p">)</span>

    <span class="n">conf_intervals_nat_upper_bound</span> <span class="o">=</span> <span class="n">theta_nat_active</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">beta_hat_nat_cov_mat</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">conf_intervals_nat_lower_bound</span> <span class="o">=</span> <span class="n">theta_nat_active</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">beta_hat_nat_cov_mat</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">conf_intervals_nat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conf_intervals_nat_lower_bound</span><span class="p">,</span> <span class="n">conf_intervals_nat_upper_bound</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">conf_intervals_std_upper_bound</span> <span class="o">=</span> <span class="n">theta_std_active</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">beta_hat_std_cov_mat</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">conf_intervals_std_lower_bound</span> <span class="o">=</span> <span class="n">theta_std_active</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">beta_hat_std_cov_mat</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">conf_intervals_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conf_intervals_std_lower_bound</span><span class="p">,</span> <span class="n">conf_intervals_std_upper_bound</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;beta_hat_nat_cov_mat&quot;</span><span class="p">:</span> <span class="n">beta_hat_nat_cov_mat</span><span class="p">,</span>
        <span class="s2">&quot;beta_hat_std_cov_mat&quot;</span><span class="p">:</span> <span class="n">beta_hat_std_cov_mat</span><span class="p">,</span>
        <span class="s2">&quot;conf_intervals_nat&quot;</span><span class="p">:</span> <span class="n">conf_intervals_nat</span><span class="p">,</span>
        <span class="s2">&quot;conf_intervals_std&quot;</span><span class="p">:</span> <span class="n">conf_intervals_std</span><span class="p">,</span>
        <span class="s2">&quot;active_set&quot;</span><span class="p">:</span> <span class="n">active_set</span><span class="p">,</span>
    <span class="p">}</span></div>


<div class="viewcode-block" id="make_prediction"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.make_prediction">[docs]</a><span class="k">def</span> <span class="nf">make_prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta_nat</span><span class="p">,</span> <span class="n">intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Helper function that takes fitted coefficients from a lasso problem and outputs fitted values on some</span>
<span class="sd">    sample data matrix X (possibly not the same as the one used for fitting). It also calculates the</span>
<span class="sd">    mean-squared-error between fitted and actual responses *y_hat* and *y*.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor (data) matrix of shape (n, p), not necessarily the same matrix that was used for fitting *theta_nat*</span>
<span class="sd">        y (np.ndarray): corresponding vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        theta_nat (np.ndarray): vector of previously fitted adaptive lasso coefficients on original scale of shape (p, )</span>
<span class="sd">        intercept (bool): logical value whether an intercept was used while fitting the adaptive lasso for *theta_nat*</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: tuple containing:</span>

<span class="sd">            **y_hat** (*np.ndarray*): fitted responses for the given sample in *X* \n</span>
<span class="sd">            **mse** (*float*): mean-squared-error between fitted and actual responses *y_hat* and *y*</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">theta_nat</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">mse</span></div>


<div class="viewcode-block" id="cv_adaptive_lasso"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.cv_adaptive_lasso">[docs]</a><span class="k">def</span> <span class="nf">cv_adaptive_lasso</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">first_stage</span><span class="o">=</span><span class="s2">&quot;OLS&quot;</span><span class="p">,</span> <span class="n">cross_valid_split</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Helper function that cross-validates the adaptive lasso in the dimensions (gamma, lambda). Two folds</span>
<span class="sd">    are used in the current implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        intercept (bool): logical value whether an intercept shall be used while fitting the adaptive lasso for *theta_nat*</span>
<span class="sd">        first_stage (str): Options are &quot;OLS&quot; and &quot;Lasso&quot; currently. Determines which method should be used for getting</span>
<span class="sd">            initial first-stage estimates for the coefficient vector. Defaults to &quot;OLS&quot;. If &quot;Lasso&quot; is chosen, the full *lamda_path* is calculated and the lamda that minimzes BIC is taken as a final estimate (for selection consistency), following **Zou, H., Hastie, T., &amp; Tibshirani, R. (2007)**</span>
<span class="sd">        cross_valid_split (bool): Option to turn-off the exchange of the two cross-validation folds, thus evaluation</span>
<span class="sd">            is only done once on the second fold, while training is done on the first fold. In small samples this is</span>
<span class="sd">            currently necessary, due to issues with float multiindexing.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: tuple containing:</span>

<span class="sd">            **cv_overview** (*pd.DataFrame*): Summary of all the possible combinations of gammas and lambdas with corresponding model performances in the differnt folds \n</span>
<span class="sd">            **params_opt** (*tuple*): Optimal tuple of (gamma_opt, lambda_opt), measured in mean-squared error loss. Element of *cv_overview*.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x_std</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="n">X_standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">x_std</span>
    <span class="n">y_standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_std</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">fold_1_idx</span><span class="p">,</span> <span class="n">fold_2_idx</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)],</span> <span class="n">indices</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="p">:]</span>
    <span class="n">X_fold_1</span><span class="p">,</span> <span class="n">X_fold_2</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">fold_1_idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">fold_2_idx</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">y_fold_1</span><span class="p">,</span> <span class="n">y_fold_2</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">fold_1_idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">fold_2_idx</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">gamma_path</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
    <span class="n">lamda_path</span> <span class="o">=</span> <span class="n">get_lamda_path</span><span class="p">(</span><span class="n">X_std</span><span class="o">=</span><span class="n">X_standardized</span><span class="p">,</span> <span class="n">y_std</span><span class="o">=</span><span class="n">y_standardized</span><span class="p">)</span>

    <span class="n">trained_on_fold_1</span> <span class="o">=</span> <span class="n">adaptive_lasso</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X_fold_1</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y_fold_1</span><span class="p">,</span>
        <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
        <span class="n">lamda_path</span><span class="o">=</span><span class="n">lamda_path</span><span class="p">,</span>
        <span class="n">gamma_path</span><span class="o">=</span><span class="n">gamma_path</span><span class="p">,</span>
        <span class="n">first_stage</span><span class="o">=</span><span class="n">first_stage</span><span class="p">,</span>
        <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">out_as_df</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">cross_valid_split</span><span class="p">:</span>
        <span class="n">trained_on_fold_2</span> <span class="o">=</span> <span class="n">adaptive_lasso</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X_fold_2</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="n">y_fold_2</span><span class="p">,</span>
            <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
            <span class="n">lamda_path</span><span class="o">=</span><span class="n">lamda_path</span><span class="p">,</span>
            <span class="n">gamma_path</span><span class="o">=</span><span class="n">gamma_path</span><span class="p">,</span>
            <span class="n">first_stage</span><span class="o">=</span><span class="n">first_stage</span><span class="p">,</span>
            <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">out_as_df</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">trained_on_fold_1</span><span class="p">[</span><span class="s2">&quot;mse_1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">trained_on_fold_2</span><span class="p">[</span><span class="s2">&quot;mse_2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

        <span class="n">prod</span> <span class="o">=</span> <span class="n">product</span><span class="p">(</span>
            <span class="n">trained_on_fold_1</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">unique</span><span class="p">(),</span>
            <span class="n">trained_on_fold_1</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="s2">&quot;lamda&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">unique</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">lamda</span> <span class="ow">in</span> <span class="n">prod</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">lamda</span><span class="p">)</span>
            <span class="n">y_hat_1</span><span class="p">,</span> <span class="n">mse_1</span> <span class="o">=</span> <span class="n">make_prediction</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_fold_2</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y_fold_2</span><span class="p">,</span>
                <span class="n">theta_nat</span><span class="o">=</span><span class="n">trained_on_fold_1</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;theta_nat&quot;</span><span class="p">],</span>
                <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">y_hat_2</span><span class="p">,</span> <span class="n">mse_2</span> <span class="o">=</span> <span class="n">make_prediction</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_fold_1</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y_fold_1</span><span class="p">,</span>
                <span class="n">theta_nat</span><span class="o">=</span><span class="n">trained_on_fold_2</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;theta_nat&quot;</span><span class="p">],</span>
                <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">trained_on_fold_1</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;mse_1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mse_1</span>
            <span class="n">trained_on_fold_2</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;mse_2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mse_2</span>

        <span class="n">cv_overview</span> <span class="o">=</span> <span class="n">trained_on_fold_1</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
            <span class="n">trained_on_fold_2</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="s2">&quot;lamda&quot;</span><span class="p">]</span>
        <span class="p">)[[</span><span class="s2">&quot;mse_1&quot;</span><span class="p">,</span> <span class="s2">&quot;mse_2&quot;</span><span class="p">]]</span>
        <span class="n">cv_overview</span><span class="p">[</span><span class="s2">&quot;mean_mse&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv_overview</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">params_opt</span> <span class="o">=</span> <span class="n">cv_overview</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span>
            <span class="n">cv_overview</span><span class="p">[</span><span class="s2">&quot;mean_mse&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">argmin</span><span class="p">(),</span>
        <span class="p">]</span><span class="o">.</span><span class="n">name</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">trained_on_fold_1</span><span class="p">[</span><span class="s2">&quot;mse_1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">prod</span> <span class="o">=</span> <span class="n">product</span><span class="p">(</span>
            <span class="n">trained_on_fold_1</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">unique</span><span class="p">(),</span>
            <span class="n">trained_on_fold_1</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="s2">&quot;lamda&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">unique</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">lamda</span> <span class="ow">in</span> <span class="n">prod</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">lamda</span><span class="p">)</span>
            <span class="n">y_hat_1</span><span class="p">,</span> <span class="n">mse_1</span> <span class="o">=</span> <span class="n">make_prediction</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_fold_2</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y_fold_2</span><span class="p">,</span>
                <span class="n">theta_nat</span><span class="o">=</span><span class="n">trained_on_fold_1</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;theta_nat&quot;</span><span class="p">],</span>
                <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">trained_on_fold_1</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="s2">&quot;mse_1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mse_1</span>

        <span class="n">cv_overview</span> <span class="o">=</span> <span class="n">trained_on_fold_1</span><span class="p">[[</span><span class="s2">&quot;mse_1&quot;</span><span class="p">]]</span>

        <span class="n">params_opt</span> <span class="o">=</span> <span class="n">cv_overview</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span>
            <span class="n">cv_overview</span><span class="p">[</span><span class="s2">&quot;mse_1&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">argmin</span><span class="p">(),</span>
        <span class="p">]</span><span class="o">.</span><span class="n">name</span>

    <span class="k">return</span> <span class="n">cv_overview</span><span class="p">,</span> <span class="n">params_opt</span></div>


<div class="viewcode-block" id="adaptive_lasso_tuned"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.adaptive_lasso_tuned">[docs]</a><span class="k">def</span> <span class="nf">adaptive_lasso_tuned</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">first_stage</span><span class="o">=</span><span class="s2">&quot;OLS&quot;</span><span class="p">,</span> <span class="n">intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cross_valid_split</span><span class="o">=</span><span class="kc">True</span>
<span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Tuned (i.e. cross-validated) version of the adaptive lasso.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (np.ndarray): regressor matrix of shape (n, p)</span>
<span class="sd">        y (np.ndarray): vector of the dependent variable *y*, of shape (n, 1)</span>
<span class="sd">        first_stage (str): Options are &quot;OLS&quot; and &quot;Lasso&quot; currently. Determines which method should be used for getting initial</span>
<span class="sd">            first-stage estimates for the coefficient vector. Defaults to &quot;OLS&quot;. If &quot;Lasso&quot; is chosen, the full *lamda_path*</span>
<span class="sd">            is calculated and the lamda that minimzes BIC is taken as a final estimate (for selection consistency),</span>
<span class="sd">            following **Zou, H., Hastie, T., &amp; Tibshirani, R. (2007)**</span>
<span class="sd">        intercept (bool): logical value whether an intercept shall be used while fitting the adaptive lasso for *theta_nat*</span>
<span class="sd">        cross_valid_split (bool): Option to turn-off the exchange of the two cross-validation folds, thus evaluation</span>
<span class="sd">            is only done once on the second fold, while training is done on the first fold. In small samples</span>
<span class="sd">            this is currrently necessary, due to issues with float multiindexing.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: dict containing:</span>

<span class="sd">            **selected_support** (*np.ndarray*): logical vector of the coefficients that are active in the optimal adaptive lasso fit \n</span>
<span class="sd">            **theta_opt_nat** (*np.ndarray*): optimal coefficient vector from fitting and cross-validating the adaptive lasso, on original scale \n</span>
<span class="sd">            **theta_opt_std** (*np.ndarray*): optimal coefficient vector from fitting and cross-validating the adaptive lasso, on standardized scale \n</span>
<span class="sd">            **conf_intervals_nat** (*np.ndarray*): elementwise confidence intervals at the 95% confidence level for optimal coefficients in the active set, on original scale \n</span>
<span class="sd">            **conf_intervals_std** (*np.ndarray*): elementwise confidence intervals at the 95% confidence level for optimal coefficients in the active set, on standardized scale</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x_std</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">y_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="n">X_standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">x_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">x_std</span>
    <span class="n">y_standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_std</span>

    <span class="n">cv_results</span><span class="p">,</span> <span class="n">params_opt</span> <span class="o">=</span> <span class="n">cv_adaptive_lasso</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
        <span class="n">first_stage</span><span class="o">=</span><span class="n">first_stage</span><span class="p">,</span>
        <span class="n">cross_valid_split</span><span class="o">=</span><span class="n">cross_valid_split</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">gamma_opt</span> <span class="o">=</span> <span class="n">params_opt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">lamda_opt</span> <span class="o">=</span> <span class="n">params_opt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">train_opt_ada_lasso</span> <span class="o">=</span> <span class="n">adaptive_lasso</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
        <span class="n">lamda_path</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">lamda_opt</span><span class="p">]),</span>
        <span class="n">gamma_path</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">gamma_opt</span><span class="p">]),</span>
        <span class="n">first_stage</span><span class="o">=</span><span class="n">first_stage</span><span class="p">,</span>
        <span class="n">num_iters</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">out_as_df</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">ada_lasso_opt_res</span> <span class="o">=</span> <span class="n">get_conf_intervals</span><span class="p">(</span>
        <span class="n">lamda</span><span class="o">=</span><span class="n">lamda_opt</span><span class="p">,</span>
        <span class="n">weights</span><span class="o">=</span><span class="n">train_opt_ada_lasso</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;gamma_weights&quot;</span><span class="p">],</span>
        <span class="n">theta_std</span><span class="o">=</span><span class="n">train_opt_ada_lasso</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;theta_std&quot;</span><span class="p">],</span>
        <span class="n">theta_nat</span><span class="o">=</span><span class="n">train_opt_ada_lasso</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;theta_nat&quot;</span><span class="p">],</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
        <span class="n">X_std</span><span class="o">=</span><span class="n">X_standardized</span><span class="p">,</span>
        <span class="n">intercept</span><span class="o">=</span><span class="n">intercept</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">y_std</span><span class="o">=</span><span class="n">y_standardized</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">selected_support</span> <span class="o">=</span> <span class="n">ada_lasso_opt_res</span><span class="p">[</span><span class="s2">&quot;active_set&quot;</span><span class="p">]</span>
    <span class="n">conf_intervals_nat</span> <span class="o">=</span> <span class="n">ada_lasso_opt_res</span><span class="p">[</span><span class="s2">&quot;conf_intervals_nat&quot;</span><span class="p">]</span>
    <span class="n">conf_intervals_std</span> <span class="o">=</span> <span class="n">ada_lasso_opt_res</span><span class="p">[</span><span class="s2">&quot;conf_intervals_std&quot;</span><span class="p">]</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;selected_support&quot;</span><span class="p">:</span> <span class="n">selected_support</span><span class="p">,</span>
        <span class="s2">&quot;theta_opt_nat&quot;</span><span class="p">:</span> <span class="n">train_opt_ada_lasso</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;theta_nat&quot;</span><span class="p">],</span>
        <span class="s2">&quot;theta_opt_std&quot;</span><span class="p">:</span> <span class="n">train_opt_ada_lasso</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;theta_std&quot;</span><span class="p">],</span>
        <span class="s2">&quot;conf_intervals_nat&quot;</span><span class="p">:</span> <span class="n">conf_intervals_nat</span><span class="p">,</span>
        <span class="s2">&quot;conf_intervals_std&quot;</span><span class="p">:</span> <span class="n">conf_intervals_std</span><span class="p">,</span>
    <span class="p">}</span></div>


<div class="viewcode-block" id="interpretable_confidence_intervals"><a class="viewcode-back" href="../../../model_code.html#src.model_code.estimators.interpretable_confidence_intervals">[docs]</a><span class="k">def</span> <span class="nf">interpretable_confidence_intervals</span><span class="p">(</span><span class="n">adaptive_lasso_tuned_obj</span><span class="p">,</span> <span class="n">intercept</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Rearranges the output from the *adaptive_lasso_tuned* method for later analysis.</span>

<span class="sd">    Args:</span>
<span class="sd">        adaptive_lasso_tuned_obj (dict): return object from a call to *adaptive_lasso_tuned*</span>
<span class="sd">        intercept (bool): logical value whether an intercept was used while fitting the adaptive lasso</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: tuple containing:</span>

<span class="sd">            (*pd.DataFrame*): contains a column of the selected_support, a column of estimated coefficients, but without the intercept, and two columns of lower- and upper confidence bounds \n</span>
<span class="sd">            (*float*): value of the estimated intercept, if *intercept* = True</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="n">theta_opt_nat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">arr</span><span class="o">=</span><span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;theta_opt_nat&quot;</span><span class="p">],</span> <span class="n">obj</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">theta_opt_nat</span> <span class="o">=</span> <span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;theta_opt_nat&quot;</span><span class="p">]</span>

    <span class="n">lower_conf_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;selected_support&quot;</span><span class="p">])],</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="p">)</span>
    <span class="n">upper_conf_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;selected_support&quot;</span><span class="p">])],</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="p">)</span>

    <span class="n">np</span><span class="o">.</span><span class="n">put</span><span class="p">(</span>
        <span class="n">a</span><span class="o">=</span><span class="n">lower_conf_bound</span><span class="p">,</span>
        <span class="n">ind</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;selected_support&quot;</span><span class="p">])[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">v</span><span class="o">=</span><span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;conf_intervals_nat&quot;</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">put</span><span class="p">(</span>
        <span class="n">a</span><span class="o">=</span><span class="n">upper_conf_bound</span><span class="p">,</span>
        <span class="n">ind</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;selected_support&quot;</span><span class="p">])[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">v</span><span class="o">=</span><span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;conf_intervals_nat&quot;</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="n">d</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;selected_support&quot;</span><span class="p">:</span> <span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;selected_support&quot;</span><span class="p">],</span>
        <span class="s2">&quot;theta_nat&quot;</span><span class="p">:</span> <span class="n">theta_opt_nat</span><span class="p">,</span>
        <span class="s2">&quot;lower_conf_bound&quot;</span><span class="p">:</span> <span class="n">lower_conf_bound</span><span class="p">,</span>
        <span class="s2">&quot;upper_conf_bound&quot;</span><span class="p">:</span> <span class="n">upper_conf_bound</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">intercept</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">),</span> <span class="n">adaptive_lasso_tuned_obj</span><span class="p">[</span><span class="s2">&quot;theta_opt_nat&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span></div>
</pre></div>

           </div>

          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021-, Josef Nagelschmidt.

    </p>
  </div>



    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a

    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>

    provided by <a href="https://readthedocs.org">Read the Docs</a>.

</footer>
        </div>
      </div>

    </section>

  </div>


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>






</body>
</html>