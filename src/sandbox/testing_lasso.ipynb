{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "economic-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "terminal-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def soft_threshold_numba(rho, lamda, w):\n",
    "    if rho < -lamda * w:\n",
    "        return rho + lamda * w\n",
    "    elif rho > lamda * w:\n",
    "        return rho - lamda * w\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opposed-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_lamda_path_numba(X, y):\n",
    "    epsilon = 0.0001\n",
    "    K = 100\n",
    "    m, p = X.shape\n",
    "\n",
    "    y = y.reshape((m, 1))\n",
    "    sx = X\n",
    "    sy = y\n",
    "\n",
    "    lambda_max = np.max(np.abs(np.sum(sx * sy, axis=0))) / m\n",
    "    lamda_path = np.exp(\n",
    "        np.linspace(np.log(lambda_max), np.log(lambda_max * epsilon), np.int64(K))\n",
    "    )\n",
    "\n",
    "    return lamda_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removable-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def count_non_zero_coeffs(theta_vec):\n",
    "    s = 0\n",
    "    for i in theta_vec:\n",
    "        if np.abs(i) > 1e-04:\n",
    "            s += 1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "binding-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def lasso_numba(\n",
    "    X,\n",
    "    y,\n",
    "    lamda_path=None,\n",
    "    penalty_factors=None,\n",
    "    theta=None,\n",
    "    num_iters=100,\n",
    "    intercept=True,\n",
    "    thresh=1e-7,\n",
    "    active_thresh=1e-7,\n",
    "    warm_start=True,\n",
    "):\n",
    "\n",
    "    m, p = X.shape\n",
    "\n",
    "    x_mean = np.zeros((p,), dtype=np.float64)\n",
    "\n",
    "    for i in range(p):\n",
    "        x_mean[i] = X[:, i].mean()\n",
    "\n",
    "    x_std = np.zeros((p,), dtype=np.float64)\n",
    "\n",
    "    for i in range(p):\n",
    "        x_std[i] = X[:, i].std()\n",
    "\n",
    "    y_mean = np.mean(y)\n",
    "    y_std = np.std(y)\n",
    "\n",
    "    X_standardized = (X - x_mean) / x_std\n",
    "    y_standardized = (y - y_mean) / y_std\n",
    "\n",
    "    if intercept:\n",
    "        X_tmp = np.ones((m, p + 1))\n",
    "        X_tmp[:, 1:] = X\n",
    "        X = X_tmp\n",
    "    \n",
    "    if lamda_path is None:\n",
    "        path = m * get_lamda_path_numba(X=X_standardized, y=y_standardized)\n",
    "    else: \n",
    "        path = m * lamda_path\n",
    "\n",
    "    if intercept:\n",
    "        X_tmp = np.ones((m, p + 1))\n",
    "        X_tmp[:, 1:] = X_standardized\n",
    "        X_standardized = X_tmp\n",
    "\n",
    "    m, p = X_standardized.shape\n",
    "\n",
    "    if theta is None:\n",
    "        theta = np.zeros((p, 1))\n",
    "\n",
    "    if penalty_factors is None:\n",
    "        penalty_factors = np.ones((p, 1))\n",
    "\n",
    "    lamdas = []\n",
    "    thetas = []\n",
    "    thetas_nat = []\n",
    "    BIC = []\n",
    "    \n",
    "    for lamda in path:\n",
    "        if not warm_start:\n",
    "            theta = np.zeros((p, 1))\n",
    "        sec_check_all_converged = False\n",
    "        active_set = np.arange(p)\n",
    "        active_set_converged = False\n",
    "\n",
    "        for _i in range(num_iters):\n",
    "            if (active_set.size != 0) and (not active_set_converged):\n",
    "                active_set_converged_check = np.full((len(active_set),), False)\n",
    "                active_set_update = np.full((len(active_set),), True)\n",
    "\n",
    "                for subindex, j in enumerate(active_set):\n",
    "                    w_j = penalty_factors[j].item()\n",
    "\n",
    "                    y_pred = X_standardized @ theta\n",
    "\n",
    "                    rho = 0.0\n",
    "                    z = 0.0\n",
    "\n",
    "                    for obs in range(m):\n",
    "                        rho += X_standardized[obs, j].item() * (\n",
    "                            y_standardized[obs].item()\n",
    "                            - y_pred[obs].item()\n",
    "                            + theta[j].item() * X_standardized[obs, j].item()\n",
    "                        )\n",
    "                        z += np.square(X_standardized[obs, j].item())\n",
    "\n",
    "                    if intercept:\n",
    "                        if j == 0:\n",
    "                            tmp = rho / z\n",
    "                            if np.abs(tmp) < active_thresh:\n",
    "                                active_set_update[subindex] = False\n",
    "                            if np.abs(theta[j] - tmp) < thresh:\n",
    "                                active_set_converged_check[subindex] = True\n",
    "                            theta[j] = tmp\n",
    "                        else:\n",
    "                            tmp = (1 / z) * soft_threshold_numba(rho, lamda, w_j)\n",
    "                            if np.abs(tmp) < active_thresh:\n",
    "                                active_set_update[subindex] = False\n",
    "                            if np.abs(theta[j] - tmp) < thresh:\n",
    "                                active_set_converged_check[subindex] = True\n",
    "                            theta[j] = tmp\n",
    "\n",
    "                    else:\n",
    "                        tmp = (1 / z) * soft_threshold_numba(rho, lamda, w_j)\n",
    "                        if np.abs(tmp) < active_thresh:\n",
    "                            active_set_update[subindex] = False\n",
    "                        if np.abs(theta[j] - tmp) < thresh:\n",
    "                            active_set_converged_check[subindex] = True\n",
    "                        theta[j] = tmp\n",
    "\n",
    "                active_set_converged = np.all(active_set_converged_check)\n",
    "                active_set = active_set[active_set_update]\n",
    "\n",
    "            elif not sec_check_all_converged:\n",
    "                active_set = np.arange(p)\n",
    "\n",
    "                active_set_converged_check = np.full((len(active_set),), False)\n",
    "                active_set_update = np.full((len(active_set),), True)\n",
    "\n",
    "                m, p = X_standardized.shape\n",
    "\n",
    "                for subindex, j in enumerate(active_set):\n",
    "                    w_j = penalty_factors[j].item()\n",
    "\n",
    "                    y_pred = X_standardized @ theta\n",
    "                    rho = 0.0\n",
    "                    z = 0.0\n",
    "\n",
    "                    for obs in range(m):\n",
    "                        rho += X_standardized[obs, j].item() * (\n",
    "                            y_standardized[obs].item()\n",
    "                            - y_pred[obs].item()\n",
    "                            + theta[j].item() * X_standardized[obs, j].item()\n",
    "                        )\n",
    "                        z += np.square(X_standardized[obs, j].item())\n",
    "\n",
    "                    if intercept:\n",
    "                        if j == 0:\n",
    "                            tmp = rho / z\n",
    "                            if np.abs(tmp) < active_thresh:\n",
    "                                active_set_update[subindex] = False\n",
    "                            if np.abs(theta[j] - tmp) < thresh:\n",
    "                                active_set_converged_check[subindex] = True\n",
    "                            theta[j] = tmp\n",
    "                        else:\n",
    "                            tmp = (1 / z) * soft_threshold_numba(rho, lamda, w_j)\n",
    "                            if np.abs(tmp) < active_thresh:\n",
    "                                active_set_update[subindex] = False\n",
    "                            if np.abs(theta[j] - tmp) < thresh:\n",
    "                                active_set_converged_check[subindex] = True\n",
    "                            theta[j] = tmp\n",
    "\n",
    "                    else:\n",
    "                        tmp = (1 / z) * soft_threshold_numba(rho, lamda, w_j)\n",
    "                        if np.abs(tmp) < active_thresh:\n",
    "                            active_set_update[subindex] = False\n",
    "                        if np.abs(theta[j] - tmp) < thresh:\n",
    "                            active_set_converged_check[subindex] = True\n",
    "                        theta[j] = tmp\n",
    "\n",
    "                active_set_converged = np.all(active_set_converged_check)\n",
    "                active_set = active_set[active_set_update]\n",
    "\n",
    "                if active_set_converged:\n",
    "                    sec_check_all_converged = True\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        if not intercept:\n",
    "            theta_tmp = theta.flatten() / x_std * y_std\n",
    "        if intercept:\n",
    "            theta_0 = (\n",
    "                theta.flatten()[0] - np.sum((x_mean / x_std) * theta.flatten()[1:])\n",
    "            ) * y_std + y_mean\n",
    "            theta_betas = theta.flatten()[1:] / x_std * y_std\n",
    "            theta_tmp = np.ones((p,))\n",
    "            theta_tmp[1:] = theta_betas\n",
    "            theta_tmp[0] = theta_0\n",
    "            \n",
    "        m, p = X.shape\n",
    "        theta_bic = np.ones((p, 1))\n",
    "        theta_bic[:,0] = theta_tmp\n",
    "        residuals_hat = np.sum(np.square(y - X @ theta_bic))\n",
    "        df_lamda = count_non_zero_coeffs(theta_vec=theta_bic.flatten())\n",
    "        BIC_lasso = residuals_hat / (m * y_std**2) + np.log(m)/ m * df_lamda\n",
    "\n",
    "        lamdas.append(lamda / m)\n",
    "        thetas.append(np.copy(theta))\n",
    "        thetas_nat.append(theta_tmp)\n",
    "        BIC.append(BIC_lasso)\n",
    "\n",
    "    return lamdas, thetas, thetas_nat, BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "correct-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)\n",
    "n = 3000\n",
    "X = np.random.rand(n,15)\n",
    "y = np.array(13* X[:,7] + X[:,3] + X[:,5] + X[:,6] +X[:,7] +X[:,8]- 1.5 * X[:,0] - 14.5 * X[:,1] + 5 + np.random.normal(0,0.5,n), dtype=np.float64).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intellectual-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('test.csv', data, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "subjective-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_learn_lasso(X, y, intercept=True, lamda_path=None):\n",
    "    \n",
    "    m, p = X.shape\n",
    "    \n",
    "    x_mean = X.mean(axis=0)\n",
    "    x_std = X.std(axis=0)\n",
    "\n",
    "    y_mean = np.mean(y)\n",
    "    y_std = np.std(y)\n",
    "\n",
    "    X_std = (X - x_mean) / x_std\n",
    "    y_std = (y - y_mean) / y_std\n",
    "\n",
    "    if lamda_path is None:\n",
    "        path = get_lamda_path_numba(X=X_std, y=y_std)\n",
    "    else: \n",
    "        path = lamda_path\n",
    "\n",
    "    y_std = y_std.flatten()\n",
    "\n",
    "    lamdas = []\n",
    "    coeffs = []\n",
    "    \n",
    "    for lamda in path:\n",
    "        reg = Lasso(alpha= lamda, fit_intercept = intercept)\n",
    "        reg.fit(X_std, y_std)\n",
    "        \n",
    "        if intercept:\n",
    "            coef = np.insert(arr=reg.coef_, obj=0, values=reg.intercept_)\n",
    "        else:\n",
    "            coef = reg.coef_\n",
    "        \n",
    "        lamdas.append(lamda)\n",
    "        coeffs.append(np.copy(coef))\n",
    "\n",
    "    return lamdas, coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eight-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_threshold(rho, lamda, w):\n",
    "    \"\"\"Soft threshold function used for normalized data and lasso regression\"\"\"\n",
    "    if rho < -lamda * w:\n",
    "        return rho + lamda * w\n",
    "    elif rho > lamda * w:\n",
    "        return rho - lamda * w\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "absent-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = naive_lasso(\n",
    "    X = X,\n",
    "    y = y,\n",
    "    lamda_path= np.array([0.01]),\n",
    "    intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "backed-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sk_learn_lasso(X = X, y = y, lamda_path = np.array([0.01]), intercept = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "better-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_intercept = lasso_numba(X = X,\n",
    "                         y = y,\n",
    "                         lamda_path = np.array([0.01]),\n",
    "                         intercept = True)\n",
    "    \n",
    "expected_result_intercept = sk_learn_lasso(X = X, y = y, intercept=True, lamda_path=np.array([0.01]))\n",
    "\n",
    "result_no_intercept = lasso_numba(X = X,\n",
    "                     y = y,\n",
    "                     lamda_path = np.array([0.01]),\n",
    "                     intercept = False)\n",
    "\n",
    "expected_result_no_intercept = sk_learn_lasso(X = X, y = y, intercept=False, lamda_path=np.array([0.01]))\n",
    "\n",
    "np.testing.assert_array_almost_equal(result_intercept[1][0].flatten(), expected_result_intercept[1][0], decimal=6)\n",
    "np.testing.assert_array_almost_equal(result_no_intercept[1][0].flatten(), expected_result_no_intercept[1][0], decimal=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "tribal-lawsuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lamda': 0.01,\n",
       "  'theta_std': array([-2.41053011e-15, -6.25255210e-02, -6.90906757e-01,  0.00000000e+00,\n",
       "          3.64002974e-02,  0.00000000e+00,  3.29210595e-02,  3.68611692e-02,\n",
       "          6.66545167e-01,  3.85717584e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00]),\n",
       "  'theta_nat': array([  5.39898735,  -1.30382941, -14.27185171,   0.        ,\n",
       "           0.76022267,   0.        ,   0.68572247,   0.76053048,\n",
       "          13.79248918,   0.79279822,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ,   0.        ,   0.        ])}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "sharp-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = lasso_numba(X = X,\n",
    "            y = y,\n",
    "            lamda_path = np.array([0.01]),\n",
    "            intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "blocked-interest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.84849372e-15, -6.25255208e-02, -6.90906757e-01,  0.00000000e+00,\n",
       "        3.64002973e-02,  0.00000000e+00,  3.29210594e-02,  3.68611692e-02,\n",
       "        6.66545167e-01,  3.85717584e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2[1][0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "toxic-swedish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0706267 ],\n",
       "       [-0.69786882],\n",
       "       [ 0.        ],\n",
       "       [ 0.04377336],\n",
       "       [ 0.        ],\n",
       "       [ 0.04102069],\n",
       "       [ 0.04497576],\n",
       "       [ 0.67379436],\n",
       "       [ 0.04647234],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(res2[1][index_lamda_opt], 0).reshape((15,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "nearby-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 280 ms, total: 1.92 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = lasso_numba(X = X, y = y, lamda_path = np.array([100, 80, 40,20 ,10,6, 5, 3, 2, 1, 0.5 , 0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "rural-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_lasso(X, y, intercept=True, lamda_path= None, gamma_path = None , first_stage = \"Lasso\", num_iters = 100):\n",
    "    \n",
    "    m, p = X.shape\n",
    "    \n",
    "    if gamma_path is None:\n",
    "        path_gamma = np.array([0.001, 0.01, 0.1, 0.5, 1, 2, 3, 4, 6, 8])\n",
    "    else:\n",
    "        path_gamma = gamma_path\n",
    "        \n",
    "    if first_stage == \"OLS\":\n",
    "        reg = LinearRegression(fit_intercept=intercept).fit(X, y)\n",
    "        coeffs = reg.coef_.T\n",
    "    elif first_stage == \"Lasso\":\n",
    "        res = lasso_numba(X = X, y = y)\n",
    "        \n",
    "        index_lamda_opt = np.where(res[3] == np.amin(res[3]))[0][0]\n",
    "        coeffs = np.delete(res[1][index_lamda_opt], 0).reshape((p,1))\n",
    "        \n",
    "    else:\n",
    "        raise AssertionError(\"This feature has so far only been implemented for OLS as its first-stage estimator.\")\n",
    "    \n",
    "    coeffs[np.abs(coeffs) < 1.00e-15] = 1.00e-15\n",
    "    \n",
    "    results = []\n",
    "    for gamma in path_gamma:\n",
    "        \n",
    "        if intercept:\n",
    "            weights = np.ones((p + 1, 1))\n",
    "            weights[1:, :] = 1.0 / np.abs(coeffs)**gamma\n",
    "        else:\n",
    "            weights = 1.0 / np.abs(coeffs)**gamma\n",
    "        \n",
    "        res = lasso_numba(X,\n",
    "                    y,\n",
    "                    lamda_path=lamda_path,\n",
    "                    penalty_factors=weights,\n",
    "                    theta=None,\n",
    "                    num_iters=num_iters,\n",
    "                    intercept=intercept,\n",
    "                    thresh=1e-7,\n",
    "                    active_thresh=1e-7,\n",
    "                    warm_start=True)\n",
    "        \n",
    "        results.append(res)\n",
    "    \n",
    "    return path_gamma, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "apart-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "latter-incidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.49 s, sys: 4.3 s, total: 5.78 s\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "real = adaptive_lasso(X = X, y= y, gamma_path = np.array([1]), lamda_path = np.array([0.0001]), first_stage = \"Lasso\")\n",
    "#real = adaptive_lasso(X = X, y= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "stretch-madrid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]),\n",
       " [([9.999999999999999e-05], [array([[-2.92377234e-15],\n",
       "           [-7.17216222e-02],\n",
       "           [-7.00123379e-01],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 4.38723755e-02],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 4.11435243e-02],\n",
       "           [ 4.51878148e-02],\n",
       "           [ 6.76071968e-01],\n",
       "           [ 4.68359152e-02],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00],\n",
       "           [ 0.00000000e+00]])], [array([  5.15611627,  -1.49559346, -14.46223667,   0.        ,\n",
       "             0.91627753,   0.        ,   0.85699062,   0.93232828,\n",
       "            13.98962256,   0.96265847,   0.        ,   0.        ,\n",
       "             0.        ,   0.        ,   0.        ,   0.        ])], [0.028341263226400813])])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-airfare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
